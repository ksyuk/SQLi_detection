{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from utils import load_dataset, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"../dataset/train.csv\")\n",
    "val_dataset = load_dataset(\"../dataset/validation.csv\")\n",
    "test_dataset = load_dataset(\"../dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "max_length = 128\n",
    "\n",
    "def create_loader_dataset(dataset, test=False):\n",
    "    queries = [data[0] for data in dataset]\n",
    "    labels = [int(data[1]) for data in dataset]\n",
    "\n",
    "    loader_dataset = []\n",
    "    for i in range(len(dataset)):\n",
    "      encoded_tokens = tokenizer(\n",
    "          queries[i],\n",
    "          max_length=max_length,\n",
    "          padding='max_length',\n",
    "          truncation=True\n",
    "      )\n",
    "      encoded_tokens['labels'] = labels[i]\n",
    "      encoded_tokens = { k: torch.tensor(v) for k, v in encoded_tokens.items() }\n",
    "      if test:\n",
    "          encoded_tokens['raw_queries'] = queries[i]\n",
    "      loader_dataset.append(encoded_tokens)\n",
    "\n",
    "    return loader_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_tarain_dataset = create_loader_dataset(train_dataset)\n",
    "loader_val_dataset = create_loader_dataset(val_dataset)\n",
    "loader_test_dataset = create_loader_dataset(test_dataset, test=True)\n",
    "\n",
    "train_loader = DataLoader(loader_tarain_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(loader_val_dataset, batch_size=256)\n",
    "test_loader = DataLoader(loader_test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name, num_labels, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bert_sc = BertForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        self.count = 0\n",
    "        self.report_freq = 90\n",
    "        self.loss_values = []\n",
    "        self.report_count = []\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        output = self.bert_sc(**batch)\n",
    "        loss = output.loss\n",
    "\n",
    "        self.count += 1\n",
    "        if self.count % self.report_freq == 0:\n",
    "            self.loss_values.append(loss.item())\n",
    "            self.report_count.append(self.count)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        output = self.bert_sc(**batch)\n",
    "        val_loss = output.loss\n",
    "        self.log('val_loss', val_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    save_weights_only=True,\n",
    "    dirpath='model/',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=3, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier(\"bert-base-uncased\", num_labels=2, lr=1e-5)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = checkpoint.best_model_path\n",
    "model = BertClassifier.load_from_checkpoint(best_model_path)\n",
    "model.bert_sc.save_pretrained('./model_transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('./model_transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
