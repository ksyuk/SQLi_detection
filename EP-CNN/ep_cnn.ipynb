{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import gensim.models\n",
    "\n",
    "from utils import load_dataset, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"./../dataset/sqli1.csv\")\n",
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset:\n",
    "    def __iter__(self):\n",
    "        for data in dataset:\n",
    "            yield data[0]\n",
    "\n",
    "word_model = gensim.models.Word2Vec(sentences=TrainDataset(), vector_size=32).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 16\n",
    "query_length = 256\n",
    "p = 128\n",
    "fill_zero = [0 for _ in range(32)]\n",
    "fill_one = [1 for _ in range(32)]\n",
    "\n",
    "def get_char_vector(query):\n",
    "    char_vec = []\n",
    "\n",
    "    if len(query) == 1:\n",
    "        try:\n",
    "            char_vec.append(word_model[query])\n",
    "        except KeyError:\n",
    "            char_vec.append(fill_one)\n",
    "    else:\n",
    "        for char in query:\n",
    "            try:\n",
    "                char_vec.append(word_model[char])\n",
    "            except KeyError:\n",
    "                char_vec.append(fill_one)\n",
    "\n",
    "            if len(char_vec) == query_length:\n",
    "                break\n",
    "    while len(char_vec) < query_length:\n",
    "        char_vec.append(fill_one)\n",
    "\n",
    "    return char_vec\n",
    "\n",
    "\n",
    "def process_batch(batch):\n",
    "    query_vec = []\n",
    "    labels = []\n",
    "\n",
    "    for query, lable in batch:\n",
    "        query_vec.append(get_char_vector(query))\n",
    "        labels.append(int(lable))\n",
    "\n",
    "    return (torch.Tensor(query_vec).view(len(batch), 1, query_length, 32),\n",
    "            torch.LongTensor(labels))\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=process_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EPCNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EPCNNClassifier, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(1, 32, kernel_size=(1, 1), padding=1)\n",
    "        self.conv1_3 = nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv1_5 = nn.Conv2d(1, 32, kernel_size=(5, 5), padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=(1, 1), padding=1)\n",
    "        self.conv2_3 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2_5 = nn.Conv2d(32, 64, kernel_size=(5, 5), padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=(3, 3), padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=(3, 3), padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(40448, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = F.relu(self.conv1_1(x))\n",
    "        x_1 = F.relu(self.conv2_1(x_1))\n",
    "        x_1 = F.max_pool2d(x_1, 2)\n",
    "        x_1 = self._common_formard(x_1)\n",
    "\n",
    "        x_3 = F.relu(self.conv1_3(x))\n",
    "        x_3 = F.relu(self.conv2_3(x_3))\n",
    "        x_3 = F.max_pool2d(x_3, 2)\n",
    "        x_3 = self._common_formard(x_3)\n",
    "\n",
    "        x_5 = F.relu(self.conv1_5(x))\n",
    "        x_5 = F.relu(self.conv2_5(x_5))\n",
    "        x_5 = F.max_pool2d(x_5, 2)\n",
    "        x_5 = self._common_formard(x_5)\n",
    "\n",
    "        x = torch.cat([x_1, x_3, x_5], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        out = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _common_formard(self, x):\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self._elastic_pool(x)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = nn.Flatten()(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _elastic_pool(self, x):\n",
    "        num_rows = x.shape[1] // p\n",
    "        return F.max_pool2d(x, (num_rows, 2))\n",
    "\n",
    "network = EPCNNClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukikase/projects/SQLi_detection/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/sjn47jks18lc1skv61gkvv640000gn/T/ipykernel_94126/3405953982.py:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  return (torch.Tensor(query_vec).view(len(batch), 1, query_length, 32),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080: accuracy=0.7504807692307692\n",
      "4160: accuracy=0.8168269230769231\n",
      "one epoch end\n",
      "4216: accuracy=0.8178368121442126\n",
      "6296: accuracy=0.8595933926302414\n",
      "8376: accuracy=0.8808500477554919\n",
      "one epoch end\n",
      "8408: accuracy=0.8813035204567079\n",
      "10488: accuracy=0.8955949656750573\n",
      "12568: accuracy=0.9053946530872056\n",
      "one epoch end\n",
      "12608: accuracy=0.9055361675126904\n",
      "14688: accuracy=0.9140795206971678\n",
      "16768: accuracy=0.9194298664122137\n",
      "one epoch end\n",
      "16808: accuracy=0.9195026178010471\n",
      "18888: accuracy=0.9251905972045743\n",
      "20968: accuracy=0.9297977871041587\n",
      "one epoch end\n",
      "21008: accuracy=0.9299314546839299\n",
      "23088: accuracy=0.9341216216216216\n",
      "25168: accuracy=0.9380165289256198\n",
      "one epoch end\n",
      "25208: accuracy=0.9381148841637575\n",
      "27288: accuracy=0.941109645265318\n",
      "29368: accuracy=0.9440888041405612\n",
      "one epoch end\n",
      "29408: accuracy=0.9441648531011969\n",
      "31488: accuracy=0.9468686483739838\n",
      "33568: accuracy=0.9492373689227837\n",
      "one epoch end\n",
      "33608: accuracy=0.9492977862413711\n",
      "35688: accuracy=0.951440260031383\n",
      "37768: accuracy=0.9533202711289981\n",
      "one epoch end\n",
      "37808: accuracy=0.9533696572154041\n",
      "39888: accuracy=0.9549739269955877\n",
      "41968: accuracy=0.9566812809759817\n",
      "one epoch end\n",
      "42008: accuracy=0.9567225290420872\n",
      "44088: accuracy=0.9583106514244238\n",
      "46168: accuracy=0.9598423150233928\n",
      "one epoch end\n",
      "46208: accuracy=0.9598770775623269\n",
      "48288: accuracy=0.9613982770046389\n",
      "50368: accuracy=0.9628136912325286\n",
      "one epoch end\n",
      "50408: accuracy=0.9628233613712109\n",
      "52488: accuracy=0.9641441853376009\n",
      "54568: accuracy=0.9654192933587451\n",
      "one epoch end\n",
      "54608: accuracy=0.9654446234983886\n",
      "56688: accuracy=0.9666066892464014\n",
      "58768: accuracy=0.9677035121154369\n",
      "one epoch end\n",
      "58808: accuracy=0.967725479526595\n",
      "60888: accuracy=0.968729470503219\n",
      "62968: accuracy=0.9696830135942066\n",
      "one epoch end\n",
      "63008: accuracy=0.9697022600304723\n",
      "65088: accuracy=0.970562930186824\n",
      "67168: accuracy=0.9714447355883754\n",
      "one epoch end\n",
      "67208: accuracy=0.9714617307463397\n",
      "69288: accuracy=0.9722318438979333\n",
      "71368: accuracy=0.9730271270036991\n",
      "one epoch end\n",
      "71408: accuracy=0.9730422361640152\n",
      "73488: accuracy=0.9738052471151752\n",
      "75568: accuracy=0.9744203895828922\n",
      "one epoch end\n",
      "75608: accuracy=0.9744339223362607\n",
      "77688: accuracy=0.9751055504067552\n",
      "79768: accuracy=0.9756920068197773\n",
      "one epoch end\n",
      "79808: accuracy=0.9757041900561347\n",
      "81888: accuracy=0.9763213169206721\n",
      "83968: accuracy=0.9768721417682927\n",
      "one epoch end\n",
      "84008: accuracy=0.9768712503571089\n",
      "86088: accuracy=0.9774184555338723\n",
      "88168: accuracy=0.9779398421195898\n",
      "one epoch end\n",
      "88208: accuracy=0.9779498458189734\n",
      "90288: accuracy=0.9784356725146199\n",
      "92368: accuracy=0.9789104451758185\n",
      "one epoch end\n",
      "92408: accuracy=0.9789195740628517\n",
      "94488: accuracy=0.9793730420794174\n",
      "96568: accuracy=0.9798069753955762\n",
      "one epoch end\n",
      "96608: accuracy=0.979815336204041\n",
      "98688: accuracy=0.9802306258106356\n",
      "100768: accuracy=0.9806287710384249\n",
      "one epoch end\n",
      "100808: accuracy=0.980636457424014\n",
      "102888: accuracy=0.9810279138480678\n",
      "104968: accuracy=0.9813657495617713\n",
      "one epoch end\n",
      "105008: accuracy=0.981372847783026\n",
      "107088: accuracy=0.9817159719109517\n",
      "109168: accuracy=0.9820643411988861\n",
      "one epoch end\n",
      "109208: accuracy=0.9820709105560033\n",
      "111288: accuracy=0.9823880382431169\n",
      "113368: accuracy=0.9827111707007269\n",
      "one epoch end\n",
      "113408: accuracy=0.9827172686230248\n",
      "115488: accuracy=0.9830285397617069\n",
      "117568: accuracy=0.9832947740881872\n",
      "one epoch end\n",
      "117608: accuracy=0.9833004557513094\n",
      "119688: accuracy=0.9835739589599626\n",
      "121768: accuracy=0.9838381183890678\n",
      "one epoch end\n",
      "121808: accuracy=0.9838434257191646\n",
      "123888: accuracy=0.984106612424125\n",
      "125968: accuracy=0.9843690461069478\n",
      "one epoch end\n",
      "126008: accuracy=0.9843740079994922\n",
      "loss=0.0023451097866337106, accurancy=0.9843740079994922\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"epoch\": 30,\n",
    "    \"optimizer\": optim.Adadelta(network.parameters(), lr=0.1),\n",
    "    \"lr_scheduler\": None,\n",
    "    \"loss_fn\": nn.CrossEntropyLoss(),\n",
    "}\n",
    "\n",
    "loss, accurancy = train(network, train_loader, device, dataset_size, 130, hyperparameters)\n",
    "print(f\"loss={loss}, accurancy={accurancy}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(network.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
